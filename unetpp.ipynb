{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os \n",
    "import numpy as np \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "from torch.utils.data import  random_split\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn.functional as F\n",
    "import albumentations as albu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path \n",
    "DATA_DIR = './data/'\n",
    "# set synthetic dataset path \n",
    "synthetic_raw_dir = \"\"\n",
    "synthetic_tag_dir = \"\"\n",
    "# set real image test dataset \n",
    "real_raw_dir  = \"\"\n",
    "real_tag_dir = \"\" \n",
    "\n",
    "x_train_dir = os.path.join(DATA_DIR, 'train')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'trainannot')\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, 'val')\n",
    "y_valid_dir = os.path.join(DATA_DIR, 'valannot')\n",
    "\n",
    "x_test_dir = os.path.join(DATA_DIR, 'test')\n",
    "y_test_dir = os.path.join(DATA_DIR, 'testannot')\n",
    "# gazebo corn mean and std \n",
    "gazebo_corn_raw_mean = [0.22065574, 0.29405924, 0.34150184]\n",
    "gazebo_corn_raw_std = [0.1133429,  0.10545158, 0.11077029]\n",
    "\n",
    "# blender corn 1 mean and std \n",
    "blender_corn_raw_mean1 = [0.4455225,  0.4115633,  0.31220761]\n",
    "blender_corn_raw_std1 = [0.13111327, 0.12116198, 0.11744572]\n",
    "\n",
    "# blender single corn 局部 mean and std \n",
    "blender_corn_raw_mean2 = [0.79994568, 0.7940369,  0.78530365]\n",
    "blender_corn_raw_std2 = [0.18375659, 0.17886415, 0.20934963]\n",
    "# blender signlecorn 整体 mean and std \n",
    "blender_corn_raw_mean3 = [0.94009896, 0.94333034, 0.93762586]\n",
    "blender_corn_raw_std3 = [0.14359212, 0.13377417, 0.15746053]\n",
    "\n",
    "# multi corn \n",
    "# Mean: [0.18631026 0.2225844  0.13032862]\n",
    "# Std: [0.1057228  0.11291125 0.08504182]\n",
    "\n",
    "# real corn field \n",
    "#Mean: [0.22904675 0.315527   0.21870158]\n",
    "#Std: [0.21330218 0.24271984 0.20648903]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "## helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "## helper function for preprocessing corn mask \n",
    "def preprocess_gazebo_corn_mask(im):\n",
    "    # convert all (0, 255, 255) to white, others to black \n",
    "    for x in range(im.width):\n",
    "        for y in range(im.height):\n",
    "            # Get the RGB value of the pixel\n",
    "            r, g, b = im.getpixel((x, y))\n",
    "            # Check if the pixel is green (has a high green component)\n",
    "            if r == 0 and g == 255 and b == 255:\n",
    "                # Convert the pixel to white\n",
    "                im.putpixel((x, y), (255, 255, 255))\n",
    "            else:\n",
    "                im.putpixel((x, y), (0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess gazebo corn mask \n",
    "def gazebo_corn_mask_preprocess(im): \n",
    "    # convert all (50,50,50) above to white, others to black \n",
    "    for x in range(im.width):\n",
    "        for y in range(im.height):\n",
    "            # Get the RGB value of the pixel\n",
    "            r, g, b = im.getpixel((x, y))\n",
    "\n",
    "            # Check if the pixel is green (has a high green component)\n",
    "            if r >50 or g>50 or b >50:\n",
    "                # Convert the pixel to white\n",
    "                im.putpixel((x, y), (255, 255, 255))\n",
    "            else:\n",
    "                im.putpixel((x, y), (0, 0, 0))\n",
    "    im = im.convert('L')\n",
    "    return im \n",
    "# preprocess gazebo corn raw\n",
    "def gazebo_corn_raw_preprocess(im): \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gazebo tree leaf preprocessing \n",
    "def gazebo_tree_mask_preprocess(im):\n",
    "    # convert all (50,50,50) above to white, others to black \n",
    "    for x in range(im.width):\n",
    "        for y in range(im.height):\n",
    "            # Get the RGB value of the pixel\n",
    "            r, g, b = im.getpixel((x, y))\n",
    "\n",
    "            # Check if the pixel is green (has a high green component)\n",
    "            if r==0 or g==255 or b  == 255:\n",
    "                # Convert the pixel to white\n",
    "                im.putpixel((x, y), (255, 255, 255))\n",
    "            else:\n",
    "                im.putpixel((x, y), (0, 0, 0))\n",
    "    im = im.convert('L')\n",
    "    return im "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess blender corn mask \n",
    "def blender_corn_mask_preprocess(im): \n",
    "    #convert rgba to rgb \n",
    "    im = im.convert('RGB')\n",
    "    width, height = im.size\n",
    "    left = (width - 960) / 2\n",
    "    top = (height - 640) / 2\n",
    "    right = (width + 960) / 2\n",
    "    bottom = (height + 640) / 2\n",
    "    # 居中裁剪\n",
    "    im = im.crop((left, top, right, bottom))\n",
    "    im = im.resize((480,320))\n",
    "    # convert all (200, 200, 200) above to white, others to black \n",
    "    for x in range(im.width):\n",
    "        for y in range(im.height):\n",
    "            # Get the RGB value of the pixel\n",
    "            r, g, b = im.getpixel((x, y))\n",
    "\n",
    "            if r >200 and g>200 and b >200:\n",
    "                # Convert the pixel to white\n",
    "                im.putpixel((x, y), (255, 255, 255))\n",
    "            else:\n",
    "                im.putpixel((x, y), (0, 0, 0))\n",
    "    im = im.convert('L')\n",
    "    return im \n",
    "# preprocess gazebo corn raw\n",
    "def blender_corn_raw_preprocess(im): \n",
    "    im = im.convert('RGB')\n",
    "    width, height = im.size\n",
    "    left = (width - 960) / 2\n",
    "    top = (height - 640) / 2\n",
    "    right = (width + 960) / 2\n",
    "    bottom = (height + 640) / 2\n",
    "    # 居中裁剪\n",
    "    im = im.crop((left, top, right, bottom))\n",
    "    im = im.resize((480,320))\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blender rand pre\n",
    "# preprocess blender corn mask \n",
    "def blender_rand_mask_preprocess(im): \n",
    "    #convert rgba to rgb \n",
    "    im = im.convert('RGB')\n",
    "    # convert all (200, 200, 200) above to white, others to black \n",
    "    for x in range(im.width):\n",
    "        for y in range(im.height):\n",
    "            # Get the RGB value of the pixel\n",
    "            r, g, b = im.getpixel((x, y))\n",
    "\n",
    "            # Check if the pixel is green (has a high green component)\n",
    "            if r >200 and g>200 and b >200:\n",
    "                # Convert the pixel to white\n",
    "                im.putpixel((x, y), (255, 255, 255))\n",
    "            else:\n",
    "                im.putpixel((x, y), (0, 0, 0))\n",
    "    im = im.convert('L')\n",
    "    return im \n",
    "# preprocess gazebo corn raw\n",
    "def blender_rand_raw_preprocess(im): \n",
    "    im = im.convert('RGB')\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class Dataset(BaseDataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            augmentation=None, \n",
    "            raw_preprocessing=None,\n",
    "            mask_preprocessing = None,\n",
    "            mean = [0.485, 0.456, 0.406],\n",
    "            std = [0.229, 0.224, 0.225]\n",
    "    ):\n",
    "        filenames = os.listdir(images_dir)\n",
    "        raw_suffix = \"_raw.png\"\n",
    "        tag_suffix = \"_tag.png\"\n",
    "        self.ids = [filename[:-len(raw_suffix)] for filename in filenames]\n",
    "        self.images_fps = [os.path.join(images_dir, f\"{image_id}{raw_suffix}\") for image_id in self.ids]\n",
    "        self.masks_fps =[os.path.join(masks_dir, f\"{image_id}{tag_suffix}\") for image_id in self.ids]\n",
    "        self.augmentation = augmentation\n",
    "        self.raw_preprocessing = raw_preprocessing\n",
    "        self.mask_preprocessing = mask_preprocessing\n",
    "        self.mean = mean \n",
    "        self.std = std \n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # read raw image \n",
    "        image = Image.open(self.images_fps[i])\n",
    "\n",
    "        # preprocessing raw image \n",
    "        if self.raw_preprocessing:\n",
    "            image = self.raw_preprocessing(image)\n",
    "        \n",
    "        # read mask iamge \n",
    "        mask = Image.open(self.masks_fps[i])\n",
    "\n",
    "        # preprocess mask image \n",
    "        if self.mask_preprocessing:\n",
    "            mask = self.mask_preprocessing(mask)\n",
    "\n",
    "        # apply augmentations to raw image \n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=np.array(image), mask=np.array(mask))\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        # convert raw image to tensor \n",
    "        raw_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=self.mean,\n",
    "                                std=self.std)\n",
    "        ])\n",
    "        image = raw_transform(image)\n",
    "        # convert black and white iamge to tensor \n",
    "        mask_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        mask = mask_transform(mask)\n",
    "        return image, mask \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1),\n",
    "                albu.RandomGamma(gamma_limit=(80, 120), p=1),\n",
    "                albu.CLAHE(p=1),\n",
    "                albu.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.Blur(blur_limit=3, p=1),\n",
    "                albu.MedianBlur(blur_limit=3, p=1),\n",
    "                albu.GaussNoise(var_limit=(10.0, 50.0), p=1),\n",
    "                albu.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.GridDistortion(p=1),\n",
    "                albu.OpticalDistortion(distort_limit=1, shift_limit=0.5, p=1),\n",
    "                albu.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "# 1280 720 => 480 320 \n",
    "def get_training_augmentation1():\n",
    "    train_transform = [\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1),\n",
    "                albu.RandomGamma(gamma_limit=(80, 120), p=1),\n",
    "                albu.CLAHE(p=0.5),\n",
    "                albu.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.Blur(blur_limit=3, p=0.5),\n",
    "                albu.MedianBlur(blur_limit=3, p=0.3),\n",
    "                albu.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "                #albu.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.GridDistortion(p=1),\n",
    "                #albu.OpticalDistortion(distort_limit=1, shift_limit=0.5, p=1),\n",
    "                #albu.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans1 = get_training_augmentation1()\n",
    "# corn blender dataset 1 稀疏\n",
    "blender_corn_dataset1 = Dataset(images_dir=\"/home/ps/leaf_seg/blender_dataset/blender_corn/raw\", masks_dir=\"/home/ps/leaf_seg/blender_dataset/blender_corn/tag\", mask_preprocessing=blender_corn_mask_preprocess,raw_preprocessing=blender_corn_raw_preprocess , augmentation=trans1)\n",
    "\n",
    "# corn blender dataset 2 局部\n",
    "blender_corn_dataset2 = Dataset(images_dir=\"/home/ps/leaf_seg/blender_dataset/blender_single_corn/raw\", masks_dir=\"/datadisk/yang/grap_dataset/blender_dataset/blender_single_corn/tag/\", mask_preprocessing=blender_corn_mask_preprocess,raw_preprocessing=blender_corn_raw_preprocess , augmentation=trans1)\n",
    "\n",
    "# corn blender dataset 3 单株整体\n",
    "blender_corn_dataset3 = Dataset(images_dir=\"/datadisk/yang/grap_dataset/blender_dataset/blender_single_corn_2/raw/\", masks_dir=\"/datadisk/yang/grap_dataset/blender_dataset/blender_single_corn_2/tag/\", mask_preprocessing=blender_corn_mask_preprocess,raw_preprocessing=blender_corn_raw_preprocess , augmentation=trans1 )\n",
    "\n",
    "# corn blender dataset 4 高密度\n",
    "blender_corn_dataset4 = Dataset(images_dir=\"/datadisk/yang/grap_dataset/blender_dataset/blender_multi_corn/raw/\", masks_dir=\"/datadisk/yang/grap_dataset/blender_dataset/blender_multi_corn/tag/\", mask_preprocessing=blender_corn_mask_preprocess,raw_preprocessing=blender_corn_raw_preprocess , augmentation=trans1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at some samples of corn blender \n",
    "to_pil_image = transforms.ToPILImage()\n",
    "image1, mask1  = blender_corn_dataset1[0]\n",
    "print (image1.shape, mask1.shape)\n",
    "uni_v = mask1.unique()\n",
    "print(uni_v)\n",
    "mask1 = to_pil_image(mask1.squeeze().cpu())\n",
    "visualize(mask = mask1)\n",
    "print(\"333\", torch.min(image1), torch.max(image1))\n",
    "image1, mask1  = blender_corn_dataset2[0]\n",
    "print (image1.shape, mask1.shape)\n",
    "uni_v = mask1.unique()\n",
    "print(uni_v)\n",
    "mask1 = to_pil_image(mask1.squeeze().cpu())\n",
    "visualize(mask = mask1)\n",
    "image1, mask1  = blender_corn_dataset3[0]\n",
    "print (image1.shape, mask1.shape)\n",
    "uni_v = mask1.unique()\n",
    "print(uni_v)\n",
    "print(\"333\", torch.min(image1), torch.max(image1))\n",
    "mask1 = to_pil_image(mask1.squeeze().cpu())\n",
    "visualize(mask = mask1)\n",
    "image1, mask1  = blender_corn_dataset4[0]\n",
    "print (image1.shape, mask1.shape)\n",
    "uni_v = mask1.unique()\n",
    "print(uni_v)\n",
    "print(\"333\", torch.min(image1), torch.max(image1))\n",
    "mask1 = to_pil_image(mask1.squeeze().cpu())\n",
    "visualize(mask = mask1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split blender dataset into 80-20 train-val \n",
    "# Calculate the lengths of train and validation sets\n",
    "train_len = int(0.8 * len(blender_corn_dataset1))\n",
    "val_len = len(blender_corn_dataset1) - train_len\n",
    "\n",
    "# Split the dataset using random_split\n",
    "train_set1, val_set1 = random_split(blender_corn_dataset1, [train_len, val_len])\n",
    "print(len(train_set1), len(val_set1))\n",
    "\n",
    "# Split the dataset using random_split\n",
    "train_len = int(0.8 * len(blender_corn_dataset2))\n",
    "val_len = len(blender_corn_dataset2) - train_len\n",
    "\n",
    "train_set2, val_set2 = random_split(blender_corn_dataset2, [train_len, val_len])\n",
    "print(len(train_set2), len(val_set2))\n",
    "\n",
    "# Split the dataset using random_split\n",
    "train_len = int(0.8 * len(blender_corn_dataset3))\n",
    "val_len = len(blender_corn_dataset3) - train_len\n",
    "train_set3, val_set3 = random_split(blender_corn_dataset3, [train_len, val_len])\n",
    "print(len(train_set3), len(val_set3))\n",
    "\n",
    "# Split the dataset using random_split\n",
    "train_len = int(0.8 * len(blender_corn_dataset4))\n",
    "val_len = len(blender_corn_dataset4) - train_len\n",
    "train_set4, val_set4 = random_split(blender_corn_dataset4, [train_len, val_len])\n",
    "print(len(train_set4), len(val_set4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader \n",
    "train_loader1 = DataLoader(train_set1, batch_size=12, shuffle=True, num_workers=12)\n",
    "valid_loader1 = DataLoader(val_set1, batch_size=2, shuffle=False, num_workers=4)\n",
    "train_loader2 = DataLoader(train_set2, batch_size=12, shuffle=True, num_workers=12)\n",
    "valid_loader2 = DataLoader(val_set2, batch_size=2, shuffle=False, num_workers=4)\n",
    "train_loader3 = DataLoader(train_set3, batch_size=12, shuffle=True, num_workers=12)\n",
    "valid_loader3 = DataLoader(val_set3, batch_size=2, shuffle=False, num_workers=4)\n",
    "train_loader4 = DataLoader(train_set4, batch_size=12, shuffle=True, num_workers=12)\n",
    "valid_loader4 = DataLoader(val_set4, batch_size=2, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'se_resnext50_32x4d'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch.utils.metrics\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.00008),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create epoch runners \n",
    "# it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model for 40 epochs\n",
    "max_score = 0\n",
    "\n",
    "round1_epoch = 15\n",
    "\n",
    "def train1Round(round, epoch, train_loader, valid_loader, lr = 0.00008 ):\n",
    "    max_score = 0\n",
    "    print(\"training round\" ,round)\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    for i in range(0, epoch):\n",
    "        print('\\nEpoch: {}'.format(i))\n",
    "        train_logs = train_epoch.run(train_loader)\n",
    "        valid_logs = valid_epoch.run(valid_loader)\n",
    "        # do something (save model, change lr, etc.)\n",
    "        if max_score < valid_logs['iou_score']:\n",
    "            max_score = valid_logs['iou_score']\n",
    "            torch.save(model, './round_' + round + '_best_model.pth')\n",
    "            print('This is the best ever model ?????')\n",
    "        if i == 15:\n",
    "            optimizer.param_groups[0]['lr'] = 1e-5\n",
    "            print('Decrease decoder learning rate to 1e-5!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'never_train.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train new dataset \n",
    "dataset_rand = Dataset(images_dir=\"/datadisk/yang/grap_dataset/blender_rand/raw/\", masks_dir=\"/datadisk/yang/grap_dataset/blender_rand/tag/\", mask_preprocessing=blender_rand_mask_preprocess,raw_preprocessing=blender_rand_raw_preprocess , augmentation=trans1 )\n",
    "train_len = int(0.8 * len(dataset_rand))\n",
    "val_len = len(dataset_rand) - train_len\n",
    "# display dataset \n",
    "to_pil_image = transforms.ToPILImage()\n",
    "image1, mask1  = dataset_rand[0]\n",
    "print (image1.shape, mask1.shape)\n",
    "uni_v = mask1.unique()\n",
    "print(uni_v)\n",
    "mask1 = to_pil_image(mask1.squeeze().cpu())\n",
    "visualize(mask = mask1)\n",
    "# Split the dataset using random_split\n",
    "train_rand, val_rand = random_split(dataset_rand, [train_len, val_len])\n",
    "print(len(train_rand), len(val_rand))\n",
    "# dataloader \n",
    "trainloader_rand = DataLoader(train_rand, batch_size=12, shuffle=True, num_workers=12)\n",
    "validloader_rand = DataLoader(val_rand, batch_size=2, shuffle=False, num_workers=4)\n",
    "\n",
    "#model = torch.load('')\n",
    "#train1Round(\"4\", 10, train_loader= train_loader4, valid_loader= valid_loader4, lr = 0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train1Round(\"no_train\", 6, train_loader=train_loader1, valid_loader=valid_loader1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1Round(\"1\", round1_epoch, train_loader=train_loader2, valid_loader=valid_loader2)\n",
    "train1Round(\"2\", round1_epoch, train_loader=train_loader3, valid_loader=valid_loader3)\n",
    "train1Round(\"3\", 15, train_loader=train_loader1, valid_loader=valid_loader1)\n",
    "train1Round(\"4\", 15, train_loader=train_loader4, valid_loader=valid_loader4)\n",
    "train1Round(\"5\", 15, train_loader=trainloader_rand, valid_loader=validloader_rand)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e21fbe6d197dc3be314437cf0aeabf8d79d62db40fefa059b153498f01c302c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
